{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the Automobile Insurance claim\n",
    "\n",
    "The purpose of an Insurance is to provide protection against the risk of any financial loss. Insurance is a form of risk management in which an insurer agrees to take the risk of the insured entity against future events, uncertain loss due to Tsunami, earthquake or damage against the vehicle or personal property. Here you will be provided with Automobile insurance claim dataset.\n",
    "\n",
    "Lets check the dataset first and import some important library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Auto_insurance.csv')#read the data from file\n",
    "df.head()#display first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape#displaying matrix of dataset so here 26 Attributes are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the dataset having mix of data numerical as well as categorical\n",
    "\n",
    "in the attributes some of attributes are very important\n",
    "here the goal of this project to make prediction model of insurence claim\n",
    "for that we need to know basic information of customer i.e Income,Monthly premium,any kind of acciedent that total amount claim of amount,vehicle class etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()#To check missing or null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good news for us there is no missing or null data in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()#now to find out the specification of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we seperate the categorical and numerical data from dataset \n",
    "first we seperate some numerical data then we hwill have to seperate the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df[['Claim Amount','Income','Monthly Premium Auto','Months Since Policy Inception','Number of Open Complaints',\n",
    "          'Number of Policies','Total Claim Amount']].copy()\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df.plot(kind='box',subplots=True,layout=(3,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Response.value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see here Response of claim insurance is 80% No and yes for 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Coverage.value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that insuranse has 60% Basics are there 30% are Extended and 10% premium based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Education.value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.EmploymentStatus.value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that in employment status 60% are employed 25% unemployed  and remaining 15% are under medical leave and retired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Policy.value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_hmap=df_new.corr()\n",
    "plt.figure(figsize=(8,7))\n",
    "sns.heatmap(corr_hmap,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the strong relation between Total claim and Monthly premium\n",
    "less in Income and total claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat=df[['Response','EmploymentStatus','Vehicle Class','Vehicle Size']].copy()\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets take categorical dataset and convert it into a numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val={'Yes':1,'No':0}\n",
    "df_cat['Response']=df_cat[\"Response\"].apply(lambda x:num_val[x])\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat=pd.get_dummies(df_cat)\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=pd.concat([df_new,df_cat],axis=1)#for combining numerical and categorical data for analysis\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreProcessing the data\n",
    "x = df_final[['Claim Amount', 'Income','Monthly Premium Auto','Months Since Policy Inception','Number of Open Complaints',\n",
    "             'Number of Policies','Response','Vehicle Class_Four-Door Car','Vehicle Class_Luxury Car','Vehicle Class_Two-Door Car',\n",
    "            'Vehicle Size_Medsize' ]]\n",
    "y=df_final['Total Claim Amount']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.40,random_state=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying ML Algorithm\n",
    "#Linear Regressor\n",
    "lm=LinearRegression()\n",
    "lm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from Linear Regressor we are getting 51% Accuracy score\n",
    "\n",
    "So this is not the good Accuracy score.\n",
    "Lets see some other Algorithm.\n",
    "\n",
    "\n",
    "Try to use some standard  Algorithm i.e GridSearchCV and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try with some other Algorithm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=np.array([1,0.1,0.01,0.0001,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we get the accuracy score is 51%.\n",
    "we get the best score on when the value of alpha is 1.\n",
    "so from GradientSerchCV we didnt get good accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from KNN Regressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(x_train,y_train)\n",
    "knn.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from KNN Regressor we are getting 54% Accuracy Score.\n",
    "\n",
    "\n",
    "now try to apply AdaBooster Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adb = AdaBoostRegressor()\n",
    "adb.fit(x_train,y_train)\n",
    "adb.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from Adabooster ,gridsearchCV ,KNN regressor we are not getting appropriate accuracy score.\n",
    "lets try some other regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "etr = ExtraTreesRegressor()\n",
    "etr.fit(x_train,y_train)\n",
    "etr.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from ExtraTree Regressor we are getting Accuracy 100% score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(x_train,y_train)\n",
    "dtr.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion-In this prediction model we can say that Decision Tree and ExtraTree Regressor is the best Algorithm for this problem \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction Model\n",
    "pred=dtr.predict(x_test)\n",
    "print(\"Predicted result price:\",pred)\n",
    "print(\"actual price\",y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rbf=RandomForestRegressor()\n",
    "rbf.fit(x_train,y_train)\n",
    "rbf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now from RBF regressor we get 91% Accuracy Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "m = SVR(gamma=\"scale\")\n",
    "m.fit(scaler.transform(x_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_pred,y):\n",
    "    y_pred = np.log(y_pred)\n",
    "    y = np.log(y)\n",
    "    return 1 - ((np.sum((y_pred-y)**2))/len(y))**1/2\n",
    "# Prediction\n",
    "y_pred = m.predict(scaler.transform(x_test))\n",
    "score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So from SVM Regressor we get 59% Accuracy Score.\n",
    " \n",
    " \n",
    " \n",
    " ExtraTree Regressor and DecisionTree Regressor we get 100% Accuracy Score.\n",
    " and from Random forest Regressor we 91% ACcuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
